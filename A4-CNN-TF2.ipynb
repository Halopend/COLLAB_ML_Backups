{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOSqkkwksNSMyqmMT7SPBuJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ySGABCRAohgq"},"source":["# Ray Tune Install for Google Collab\n","**Please run the below code to setup ray in a collab environmet.**\n","\n","Since ray is not installed by default, and there's a issue with the pre-installed version of pyarrow the below code should handle the installation process so run-all can work nicely. **Note that the first time it's ran, the system will say there was a crash (this is what the os exit step is for). This is on purpose to reload the system.**\n","\n"]},{"cell_type":"code","metadata":{"id":"C-REKrVfoteE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"829a542b-bfa7-49e8-ccb3-a7f7288fc79c"},"source":["try:\n","  import ray\n","except:\n","  ## needed due to an incompatibility with collab\n","  !pip uninstall -y -q pyarrow\n","  !pip install -q https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.8.0.dev5-cp36-cp36m-manylinux1_x86_64.whl\n","  !pip install -q ray[debug]\n","\n","  import os\n","  os._exit(0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: ray-0.8.0.dev5-cp36-cp36m-manylinux1_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: ray 2.3.1 does not provide the extra 'debug'\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"c20fRLPgSOnt"},"source":["  # This is so we can run ngrok tunnels if desired so we can view tensorboard in a new tab\n","  !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","  !unzip ngrok-stable-linux-amd64.zip\n","\n","  LOG_DIR = './logs'\n","  get_ipython().system_raw(\n","      'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","      .format(LOG_DIR)\n","  )\n","\n","  ! echo \"### If you want to view tensorboard in a new tab, use this link:\"\n","  ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","        \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y2jtK18ZTfuO"},"source":["# !pkill tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IENj234UOeR4"},"source":["## Tensorboard Setup/Run\n","Tensorboard is a way to visualize/examine the parameters of the data and can be very useful for organizing/examining the data. In addition to providing a web interface for viewing data, it also automatically generates csv files which can be very useful for later viewing the data. "]},{"cell_type":"code","metadata":{"id":"m7vNdlc1PPxY"},"source":["import datetime, os, shutil\n","LOG_DIR = \"./logs\"\n","# shutil.rmtree(logs_base_dir, ignore_errors=True, onerror=None)\n","os.makedirs(LOG_DIR, exist_ok=True)\n","%load_ext tensorboard\n","%tensorboard --logdir {LOG_DIR}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1dTj1JDkw9Qz"},"source":["# Import Data\n","\n","Here we load the cifar-10 dataset and transform it using binary categorization style matrices"]},{"cell_type":"code","metadata":{"id":"988tw2-UxI3H"},"source":["import tensorflow as tf\n","import numpy as np\n","\n","imgW,imgH = 32,32\n","channel_depth = 3\n","numOfCategories = 10\n","\n","\n","# Load data\n","def load_data(nb_classes=10):\n","    from keras.datasets import cifar10\n","    from keras.utils import np_utils\n","    from keras import backend\n","    backend.set_image_data_format('channels_last')   \n","    # the data, shuffled and split between train and test sets\n","    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","\n","    def prepare_X(X):\n","        return X.astype('float32') / 255\n","\n","    X_train, X_test = [prepare_X(X) for X in (X_train, X_test)]\n","    print(X_train.shape[0], 'train image samples of shape: ', X_train.shape[1:])\n","    print(X_test.shape[0], 'test samples')\n","\n","    # convert class vectors to binary class matrices (basically one hot)\n","    Y_train = np_utils.to_categorical(y_train, nb_classes)\n","    Y_test = np_utils.to_categorical(y_test, nb_classes)\n","\n","    w = X_train[0].shape[0]\n","    h = X_train[0].shape[1]\n","\n","\n","    # Fixes datasets whose shape doesn't imply depth (example, MNIST shape is 28x28 instead of 28,28,1) as they are 2D\n","    if (np.size(X_train[0].shape) == 2):\n","      X_train = X_train.reshape(-1, w, h, channel_depth)  # 28x28x1 input img (in the case of MNIST)\n","      X_test = X_test.reshape(-1, w, h,   channel_depth)  # 28x28x1 input img (in the case of MNIST)    \n","    \n","    return X_train, Y_train, X_test, Y_test, (w,h)\n","\n","trX, trY, teX, teY, shape = load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JHuoIG7xRKVH"},"source":["## Ray Tune Setup\n","The app tune by ray is a great way to run multiple testing/trainings with various parameters adjusted. by naming each training session based on the parameters we will be comparing to each other, we will be able to visualize the various setups in an organized way through our above tensorboard integration."]},{"cell_type":"code","metadata":{"id":"TWbA5K6rSWED"},"source":["import ray\n","from ray import tune\n","\n","import math\n","import io\n","\n","\n","############ Matplot Helper Functions ############\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","plt.switch_backend('agg') ### Let's us store the matplot images inside of tensorboard (useful for organizing data)\n","\n","def plot_to_tf_image(figure):\n","    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n","    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n","    # Save the plot to a PNG in memory.\n","    buf = io.BytesIO()\n","    plt.savefig(buf, format='png')\n","    # Closing the figure prevents it from being displayed directly inside\n","    # the notebook.\n","    plt.close(figure)\n","    buf.seek(0)\n","    # Convert PNG buffer to TF image\n","    image = tf.image.decode_png(buf.getvalue(), channels=4)\n","    # Add the batch dimension\n","    image = tf.expand_dims(image, 0)\n","    return image\n","\n","\n","#########################################################################################\n","######################## Generalized Helper Function ####################################\n","######## Creates clases dynamically using just a class string and dynamicClassCreater(\"name.of.class.type\")(param,param2=test,...)\n","### this is useful in cases where you can only pass a string inside another deeply nested function you want to have variable classinstances of\n","#  Ex: passing an optimizer with variable parameters through a config file into ray tune (which note is multi-threaded process)\n","#  Using this convenience function, you can have classes a parameter within a ray tune config since you can supply an array of strings.\n","def dynamicClassCreater(class_str):\n","    from importlib import import_module\n","    try:\n","        module_path, class_name = class_str.rsplit('.', 1)\n","        module = import_module(module_path)\n","        return getattr(module, class_name)\n","    except (ImportError, AttributeError) as e:\n","        raise ImportError(class_str)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LBx8yDpGfnuw"},"source":["## Callback Class Definitions\n","Tensorflow 2.0 has a nice callback feature we can use to inject a list of functions which which run at the end of an epoch (or batch depening on settings) so here we define few we may want to add later. Note that accuracy logger callback from below is a CUSTOMIMZED callback which expects an extra parameter supplied inorder to be created.\n","\n"]},{"cell_type":"code","metadata":{"id":"KoBsz9REfyYP"},"source":["#########################################################################################\n","######################## MODEL CALLBACKS ################################################\n","######## Tensorflow 2.0 has a nice option of supplying callbacks that can be run at the end of each epoch\n","### in-order to speed things along, we will be creating useful callback here we can use\n","# for everything from logging into tensorboard, stopping a training session automatically and\n","# more.\n","\n","STOPPING_PARAMETER = 'mse'\n","STOPPING_VALUE = 0.02\n","class StopperMseCallback(tf.keras.callbacks.Callback):\n","    def __init__(self):\n","        self.skipcount = 0\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.skipcount+=1\n","        if (self.skipcount > 5):\n","            self.skipcount = 0\n","            res, test = self.model.evaluate()\n","            print(\"MODEL BEING EVALUATED\")\n","            print (res)\n","            try:\n","                if(logs.get(STOPPING_PARAMETER) < STOPPING_VALUE):   \n","                    self.model.stop_training = True\n","            except:\n","                print(STOPPING_PARAMETER + \" not found\\n\")\n","\n","\n","class AccuracyLoggerCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, directory):\n","        self.directory = directory\n","\n","    def on_train_end(self, epoch, logs={}): \n","        accuracy, mse, _ = self.model.evaluate(teX,teY)\n","        # Add image to tb summary\n","        writer = tf.summary.create_file_writer(self.directory)\n","        with writer.as_default():\n","            tf.summary.scalar(\n","                \"sanity_accuracy\",\n","                accuracy,\n","                step=1,\n","                description=\"Accuracy from testing at end of training\"\n","        )\n","            \n","### example usage of AccuracyLoggerCallback being passed the correct directory for proper tensorboard integration\n","# AccuracyLoggerCallback(reporter._logdir)       \n","            \n","from ray.tune import track\n","class TuneReporterCallback(tf.keras.callbacks.Callback):\n","    \"\"\"Tune Callback for Keras.\"\"\"\n","\n","    def __init__(self, reporter=None, freq=\"batch\", logs={}):\n","        \"\"\"Initializer.\n","        Args:\n","            reporter (StatusReporter|tune.track.log|None): Tune object for\n","                returning results.\n","            freq (str): Sets the frequency of reporting intermediate results.\n","                One of [\"batch\", \"epoch\"].\n","        \"\"\"\n","        self.reporter = reporter or track.log\n","        self.iteration = 0\n","        \n","        if freq not in [\"batch\", \"epoch\"]:\n","            raise ValueError(\"{} not supported as a frequency.\".format(freq))\n","        self.freq = freq\n","        super(TuneReporterCallback, self).__init__()\n","\n","    def on_batch_end(self, batch, logs={}):\n","        if not self.freq == \"batch\":\n","            return\n","        self.iteration += 1\n","        for metric in list(logs):\n","            if \"loss\" in metric and \"neg_\" not in metric:\n","                logs[\"neg_\" + metric] = -logs[metric]\n","        if \"acc\" in logs:\n","            self.reporter(keras_info=logs, mean_accuracy=logs[\"acc\"])\n","        else:\n","            self.reporter(keras_info=logs, mean_accuracy=logs.get(\"accuracy\"))\n","\n","    def on_epoch_end(self, batch, logs={}):\n","        if not self.freq == \"epoch\":\n","            return\n","        self.iteration += 1\n","        for metric in list(logs):\n","            if \"loss\" in metric and \"neg_\" not in metric:\n","                logs[\"neg_\" + metric] = -logs[metric]\n","        if \"acc\" in logs:\n","            self.reporter(keras_info=logs, mean_accuracy=logs[\"acc\"])\n","        else:\n","            self.reporter(keras_info=logs, mean_accuracy=logs.get(\"accuracy\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5FLGmSk6hEbM"},"source":["# Model Configuration\n","Here we are setting what we are going to actually test/run inside ray tune. Note that tune allows ofr us to define multiple runs of model training with different parameters."]},{"cell_type":"code","metadata":{"id":"dL7CMOtohEyN"},"source":["\n","### The default value to be used if none is defined within the config\n","EPOCH = 15;\n","\n","def tuneModelInitialize(config, reporter):\n","    import tensorflow as tf\n","    from ray.tune import track\n","    from tensorflow.keras.callbacks import EarlyStopping\n","\n","\n","    ## Model initialization\n","    model = tf.keras.models.Sequential()\n","    optimizer = tf.keras.optimizers.Adam()\n","    loss = tf.keras.losses.CategoricalCrossentropy()\n","    metrics = [\"categorical_accuracy\",\"mse\",]\n","    earlyStopCB = EarlyStopping(monitor='val_categorical_accuracy', mode='max', verbose=1, patience=80)\n","    callbacks = [TuneReporterCallback(reporter,freq=\"epoch\"),earlyStopCB]\n","\n","\n","    ## Example of using dynamicClassCreater to generate an optimizer with parameters to feed into the model inside the thread.\n","    ## optimizer = dynamicClassCreater(\"tensorflow.keras.optimizers.\" + config[\"optimizer\"])(lr=config[\"lr\"],momentum=config[\"momentum\"],)\n","\n","\n","    try:\n","      epochs = config['epoch']\n","    except:\n","      epochs = EPOCH\n","\n","    # convience function for compiling/running the model based on the above paramters.\n","    def compile_and_fit(model):\n","      model.compile(loss=loss, optimizer=optimizer , metrics=metrics)\n","      model.summary() ## convenience function to printout the model shape\n","\n","      model.fit(\n","        trX,\n","        trY,\n","        # batch_size=batch_size,\n","        epochs=epochs,\n","        verbose=2,\n","        validation_data=(teX, teY),\n","        validation_freq=20,\n","        callbacks= callbacks\n","      )\n","\n","\n","    ###########################################################################################\n","    #################################### Model Structuring ####################################\n","    ###########################################################################################\n","    # This section is where we define all the structure of our NN, using the infor gathered from\n","    # the configs to actually determine the shape of things\n","    \n","    model.add(tf.keras.layers.Input((imgW, imgW, channel_depth)))   ### since our image determines the shape of the input and it's the same for each question, we are adding this layer here just to define the sizing parameters for tf to determine shaping on the next layer\n","\n","    #### Since ray tune can't pass multiple varied models down inside the callback, we will hardcode the variations of the questions here, and then use the configs passed in to determine which model to use\n","    if (config['name'] == 'Q3.1'):\n","        ## this is used to create the tester for Q1. Since we don't really have a starting point, we'll just pick a reasonable number of conv filters (10/layer) with 5x5 kernels, and a halving between convolutions using maxpool.\n","        ## becuase we want to hopefully grab more subfeatures the deeper we get (cause after pooling, the calculations aren't as expensive we add more layers)\n","        for index in range(config['num_conv_layers']):\n","            model.add(tf.keras.layers.Conv2D(tf.dtypes.cast(8**(index+1), tf.int32), kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='same', name='L{}_Conv2D_10x5x5'.format(index)))\n","            model.add(tf.keras.layers.MaxPooling2D(pool_size=1, strides=2, padding='valid', name='L{}_MaxPool2D_halved'.format(index)))\n","\n","        currentLayer = config['num_conv_layers'] + 1\n","        ### here we flatten our 3 layered convolved outputs to fully connect them to our final step.\n","        model.add(tf.keras.layers.Flatten())\n","        model.add(tf.keras.layers.Dense(100, activation='relu', name='L{}_Relu_{}'.format(currentLayer,100)))\n","        model.add(tf.keras.layers.Dense(numOfCategories, activation='softmax', name = 'Output'))\n","\n","\n","\n","\n","    elif (config['name'] == \"Q3.2\" and config['mode'] == 'testing'):\n","        ## this will be used to create the combinations of all the variation of the layer sizes we want to test\n","        for i, conv_layer_depth in enumerate(config['cnn_features']):\n","          model.add(tf.keras.layers.Conv2D(conv_layer_depth, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding= 'same'))\n","          model.add(tf.keras.layers.MaxPool2D(pool_size=1, strides=2, padding='valid'))\n","    \n","\n","        ### here we flatten our 3 layered convolved outputs to fully connect them to our final step.\n","        model.add(tf.keras.layers.Flatten())\n","        model.add(tf.keras.layers.Dense(100, activation='relu', name='L4_Relu'))\n","        model.add(tf.keras.layers.Dense(numOfCategories, activation='softmax', name = 'Output'))\n","\n","\n","\n","    elif (config['name'] == \"Q3.2\" and config['mode'] == 'final'):\n","        ## this will be used to create the combinations of all the variation of the layer sizes we want to test\n","        for i, conv_layer_depth in enumerate(config['cnn_features']):\n","          model.add(tf.keras.layers.Conv2D(conv_layer_depth, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding= 'same'))\n","          model.add(tf.keras.layers.MaxPool2D(pool_size=1, strides=2, padding='valid'))\n","          model.add(tf.keras.layers.Dropout(rate=i*0.25))\n","    \n","\n","        ### here we flatten our 3 layered convolved outputs to fully connect them to our final step.\n","        model.add(tf.keras.layers.Flatten())\n","        model.add(tf.keras.layers.Dense(120, activation='relu', name='L4_Relu'))\n","        model.add(tf.keras.layers.Dense(numOfCategories, activation='softmax', name = 'Output'))\n","\n","\n","    compile_and_fit(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYbibCwme3dS"},"source":["## Since we will be using tensorboard to read all the data, this is a nice way to setup the naming scheme so we can filter the parameters\n","def trial_str_creator(trial):\n","    return \"{}_config={}_trial_id={}\".format(trial.config['name'],trial.experiment_tag, trial.trial_id)\n","\n","def testRunner(config):\n","    tune.run(\n","        tuneModelInitialize,\n","        trial_name_creator = trial_str_creator,\n","        local_dir = logs_base_dir,\n","        resources_per_trial={\n","            \"cpu\": 2,\n","            \"gpu\": 1\n","        },\n","        verbose=1,\n","        config=config,\n","        num_samples=1,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nKAUPMrily9f"},"source":["try:\n","    tf.get_logger().setLevel('INFO')\n","except Exception as exc:\n","    print(exc)\n","import warnings\n","warnings.simplefilter(\"ignore\")\n","\n","\n","## Final Magic Step. Spins up the various configs\n","ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n","ray.init(\n","    local_mode=True,\n","    memory=9000 * 1024 * 1024,\n","    object_store_memory=200 * 1024 * 1024,\n","    driver_object_store_memory=100 * 1024 * 1024,\n","    log_to_driver=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A--04VqvhCvk"},"source":["#################################### MODEL Parameters / Configuration ####################################\n","## These are the configurations of all our various networks/parameters we want to test.\n","## \n","testing_configs = [\n","  ## Q3.1\n","  {\n","              \"name\":     \"Q3.1\",\n","              \"threads\": 1,\n","              \"num_conv_layers\":    tune.grid_search([1,2,3]),\n","  },\n","  ### Q3.2\n","  ## since we are only testing here to compare approximate values, but we are doing a large number of test to get at the interplay between grids, \n","  ## we don't want too many epochs to muddy the amount of calculations performed\n","\n","  {\n","              \"name\":     \"Q3.2\",\n","              \"threads\": 1,\n","              \"mode\":         \"testing\",\n","              \"epoch\":        10,\n","              \"cnn_features\": [\n","                  tune.sample_from(lambda spec: np.random.randint(21,23)),\n","                  tune.sample_from(lambda spec: np.random.randint(44,50)),\n","                  tune.sample_from(lambda spec: np.random.randint(115,125) ),\n","               ],\n","  },\n","]\n","\n","# for config in model_configs:\n","#     testRunner(config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EI7E_La3UEYo"},"source":["## Now that we know the size we want we'll test the various parameters\n","final_config = {\n","              \"name\":     \"Q3.2\",\n","              \"threads\": 1,\n","              \"mode\":         \"final\",\n","              \"epoch\":        1000,\n","              \"cnn_features\": [\n","                  tune.grid_search([22]),\n","                  tune.grid_search([32]),\n","                  tune.grid_search([128]),\n","               ],\n","  }\n","\n","testRunner(final_config)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6K0snjD6lgZp"},"source":["import shutil\n","shutil.make_archive('Q2', 'zip', LOG_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FtoDAhe-CJ6S"},"source":["import os\n","os._exit(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZpTzf-imACR"},"source":["from google.colab import files\n","files.download(\"Q2.zip\")"],"execution_count":null,"outputs":[]}]}